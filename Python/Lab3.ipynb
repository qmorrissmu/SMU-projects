{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Extending Logistic Regression\n",
    "\n",
    "### By: Quentin Morris, Arkadijs Slobodkins, Daniel Willborn\n",
    "\n",
    "#### Business Understanding:\n",
    "\n",
    "This is a dataset containing the various chemical attributes of red wine and their quality assignment taken from the following website: https://archive.ics.uci.edu/ml/datasets/Wine. The purpose of using this dataset is to apply machine learning to find correlations between each wine's chemical attributes and their respective quality, and be able to then have a program determine the quality of the wine based on its chemical data. The application for this would be that it could allow wineries to make a more objective determination on the quality of their wines, allowing them to better optimise their products based on chemical composition. Wineries who use this classification model would be able to determine wine quality before the product has to be shipped to them, allowing for more efficient picking of products. It would also allow them to determine prices they are willing to pay versus the shipping costs of wines so they can guarantee a profit margin of their liking while still paying the seller a valid price based on quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "wine_data = pd.read_csv('winequality-white.csv', sep=\";\")\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>quality_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.186275</td>\n",
       "      <td>0.216867</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.149826</td>\n",
       "      <td>0.373550</td>\n",
       "      <td>0.267785</td>\n",
       "      <td>0.254545</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.240385</td>\n",
       "      <td>0.215686</td>\n",
       "      <td>0.204819</td>\n",
       "      <td>0.015337</td>\n",
       "      <td>0.118694</td>\n",
       "      <td>0.041812</td>\n",
       "      <td>0.285383</td>\n",
       "      <td>0.132832</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.313953</td>\n",
       "      <td>0.241935</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.413462</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.096626</td>\n",
       "      <td>0.121662</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.204176</td>\n",
       "      <td>0.154039</td>\n",
       "      <td>0.490909</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.192771</td>\n",
       "      <td>0.121166</td>\n",
       "      <td>0.145401</td>\n",
       "      <td>0.156794</td>\n",
       "      <td>0.410673</td>\n",
       "      <td>0.163678</td>\n",
       "      <td>0.427273</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0       0.307692          0.186275     0.216867        0.308282   0.106825   \n",
       "1       0.240385          0.215686     0.204819        0.015337   0.118694   \n",
       "2       0.413462          0.196078     0.240964        0.096626   0.121662   \n",
       "3       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "4       0.326923          0.147059     0.192771        0.121166   0.145401   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide   density        pH  sulphates  \\\n",
       "0             0.149826              0.373550  0.267785  0.254545   0.267442   \n",
       "1             0.041812              0.285383  0.132832  0.527273   0.313953   \n",
       "2             0.097561              0.204176  0.154039  0.490909   0.255814   \n",
       "3             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
       "4             0.156794              0.410673  0.163678  0.427273   0.209302   \n",
       "\n",
       "    alcohol  quality quality_rating  \n",
       "0  0.129032        6              3  \n",
       "1  0.241935        6              3  \n",
       "2  0.338710        6              3  \n",
       "3  0.306452        6              3  \n",
       "4  0.306452        6              3  "
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#used this source to normalize feature data between 0 and 1 using minmaxscaler\n",
    "#https://stackoverflow.com/questions/43834242/sklearn-minmaxscaler-scale-specific-columns-only\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "wine_data[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']] = minmax_scale(wine_data[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']])\n",
    "# let's break up the age variable\n",
    "wine_data['quality_rating'] = pd.cut(wine_data['quality'],[0,4,5,6,9],\n",
    "                                 labels=[1,2,3,4]) # this creates a new variable\n",
    "wine_data.quality_rating.describe()\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts of Quality in Entire Dataset:\n",
      " 3    2198\n",
      "2    1457\n",
      "4    1060\n",
      "1     183\n",
      "Name: quality_rating, dtype: int64\n",
      "Counts of Quality in Training Dataset:\n",
      " 3    1760\n",
      "2    1170\n",
      "4     838\n",
      "1     150\n",
      "Name: quality_rating, dtype: int64\n",
      "Counts of Quality in Testing Dataset:\n",
      " 3    438\n",
      "2    287\n",
      "4    222\n",
      "1     33\n",
      "Name: quality_rating, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#used this link for train_test_split\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine_features = wine_data[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']]\n",
    "wine_target = wine_data[['quality_rating']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_features, wine_target, test_size = 0.2)\n",
    "print('Counts of Quality in Entire Dataset:\\n',wine_target['quality_rating'].value_counts())\n",
    "print('Counts of Quality in Training Dataset:\\n',y_train['quality_rating'].value_counts())\n",
    "print('Counts of Quality in Testing Dataset:\\n',y_test['quality_rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "vars_to_use = ['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol','quality'] # pick vars\n",
    "plt.pcolor(wine_data[vars_to_use].corr()) # do the feature correlation plot\n",
    "\n",
    "# fill in the indices\n",
    "plt.yticks(np.arange(0.5, len(vars_to_use), 1), vars_to_use)\n",
    "plt.xticks(np.arange(0.5, len(vars_to_use), 1), vars_to_use)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description of Final Dataset\n",
    "The dataset is unbalanced in the quality attribute, the feature we are looking to classify wines by, which influenced us to make the decision to group qualities together. Originally, most of the wines have qualities of 5 and 6. We figured we should bin together some of the wines below 5 and above 6 in order to get a better sampling of poor and excellent wines for out regression classifier. We tried a number of splits to keep 5 and 6 seperate, but keeping them together seemed to produce the best results showing they must be very similar in their attributes. Some of the features in the dataset have much larger values than others (total sulfur dioxide and sulphates for example, see first wine_data.head()) which could affect the weights formed during regression, so we normalized the data to fall between 0 and 1. There are not any clear indicators of features that correlate highly to quality besides alcohol content, so we did not get rid of any features to give the model more features to look at for classification and possibly provide better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Argument for 80/20 split\n",
    "\n",
    "For our dataset an 80/20 split seems like a fair split decision. The distribution of qualities is consistent from the entire datset to our 80/20 train/test split, showing that this would be a valid splitting method. If our data was represented over time, say alcohol levels at different months of fermentation, an 80/20 split may capture many low alcohol levels in the train split and only see high alcohol levels in the test split which would confuse the classifier later on. The data is static, not time series data, so there will not be any time discrepancies to worry about from the training to testing split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Binary Logistic Regression Object, Not Trainable\n"
     ]
    }
   ],
   "source": [
    "#used notebook from class to implement Binary Logistic Regression\n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/05.%20Logistic%20Regression.ipynb\n",
    "#begin binary logistic regression\n",
    "\n",
    "import numpy as np\n",
    "class BinaryLogisticRegressionBase:\n",
    "    # private:\n",
    "    def __init__(self, eta, iterations=20, C=0.1):\n",
    "        self.C = C\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'Base Binary Logistic Regression Object, Not Trainable'\n",
    "    \n",
    "    # convenience, private and static:\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        return 1/(1+np.exp(-theta)) \n",
    "    \n",
    "    @staticmethod\n",
    "    def _add_bias(X):\n",
    "        return np.hstack((np.ones((X.shape[0],1)),X)) # add bias term\n",
    "    \n",
    "    # public:\n",
    "    def predict_proba(self, X, add_bias=True):\n",
    "        # add bias term if requested\n",
    "        Xb = self._add_bias(X) if add_bias else X\n",
    "        return self._sigmoid(Xb @ self.w_) # return the probability y=1\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return (self.predict_proba(X)>0.5) #return the actual prediction\n",
    "    \n",
    "    \n",
    "        \n",
    "blr = BinaryLogisticRegressionBase(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained Binary Logistic Regression Object\n"
     ]
    }
   ],
   "source": [
    "#used notebook from class to implement Binary Logistic Regression\n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/05.%20Logistic%20Regression.ipynb\n",
    "\n",
    "#addding the model training function\n",
    "# inherit from base class\n",
    "import pdb\n",
    "class BinaryLogisticRegression(BinaryLogisticRegressionBase):\n",
    "    #private:\n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'Binary Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained Binary Logistic Regression Object'\n",
    "        \n",
    "    def _get_gradient(self,X,y):\n",
    "        # programming \\sum_i (yi-g(xi))xi\n",
    "        gradient = np.zeros(self.w_.shape) # set gradient to zero\n",
    "        for (xi,yi) in zip(X,y):\n",
    "            # the actual update inside of sum\n",
    "            #pdb.set_trace()\n",
    "            gradi = (yi - self.predict_proba(xi,add_bias=False))*xi \n",
    "            # reshape to be column vector and add to gradient\n",
    "            gradient += gradi.reshape(self.w_.shape) \n",
    "        \n",
    "        return gradient/float(len(y))\n",
    "       \n",
    "    # public:\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X) # add bias term\n",
    "        num_samples, num_features = Xb.shape\n",
    "        \n",
    "        self.w_ = np.zeros((num_features,1)) # init weight vector to zeros\n",
    "        \n",
    "        # for as many as the max iterations\n",
    "        for _ in range(self.iters):\n",
    "            gradient = self._get_gradient(Xb,y)\n",
    "            self.w_ += gradient*self.eta # multiply by learning rate \n",
    "\n",
    "            \n",
    "blr = BinaryLogisticRegression(0.1)\n",
    "print(blr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of:  0.6651694569211923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_b = wine_features.to_numpy()\n",
    "y_b = (wine_target.to_numpy()>2).astype(np.int)\n",
    "\n",
    "blr = BinaryLogisticRegression(eta=0.1,iterations=10)\n",
    "blr.fit(X_b,y_b)\n",
    "yhat = blr.predict(X_b)\n",
    "print('Accuracy of: ',accuracy_score(y_b,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07297558]\n",
      " [0.01971832]\n",
      " [0.00887427]\n",
      " [0.01474146]\n",
      " [0.00474061]\n",
      " [0.00523051]\n",
      " [0.00837952]\n",
      " [0.01785515]\n",
      " [0.00612678]\n",
      " [0.03371323]\n",
      " [0.02441715]\n",
      " [0.04697101]]\n",
      "Accuracy of:  0.673469387755102\n"
     ]
    }
   ],
   "source": [
    "#used notebook from class to implement Vectorized Binary Logistic Regression\n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/05.%20Logistic%20Regression.ipynb\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "params = dict(eta=0.001, iterations=500)\n",
    "\n",
    "class VectorBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # inherit from our previous class to get same functionality\n",
    "    @staticmethod\n",
    "    def _sigmoid(theta):\n",
    "        # increase stability, redefine sigmoid operation\n",
    "        return expit(theta) #1/(1+np.exp(-theta))\n",
    "    \n",
    "    # but overwrite the gradient calculation\n",
    "    def _get_gradient(self,X,y):\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        gradient = np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        \n",
    "        return gradient.reshape(self.w_.shape)\n",
    "\n",
    "# use same params as defined above\n",
    "blr = VectorBinaryLogisticRegression(**params)\n",
    "blr.fit(X_train.to_numpy(),(y_train.quality_rating.to_numpy()>2))\n",
    "print(blr.w_)\n",
    "yhat = blr.predict(X_test.to_numpy())\n",
    "print('Accuracy of: ',accuracy_score(y_test.quality_rating.to_numpy()>2,yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used notebook from class to implement Multiclass Logistic Regression\n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/05.%20Logistic%20Regression.ipynb\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, eta, iterations=20,C=0.1):\n",
    "        self.eta = eta\n",
    "        self.iters = iterations\n",
    "        self.C=C\n",
    "        # internally we will store the weights as self.w_ to keep with sklearn conventions\n",
    "    \n",
    "    def __str__(self):\n",
    "        if(hasattr(self,'w_')):\n",
    "            return 'MultiClass Logistic Regression Object with coefficients:\\n'+ str(self.w_) # is we have trained the object\n",
    "        else:\n",
    "            return 'Untrained MultiClass Logistic Regression Object'\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = (y==yval) # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = VectorBinaryLogisticRegression(self.eta,\n",
    "                                                 self.iters)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T\n",
    "        \n",
    "    def predict_proba(self,X):\n",
    "        probs = []\n",
    "        for blr in self.classifiers_:\n",
    "            probs.append(blr.predict_proba(X)) # get probability for each classifier\n",
    "        \n",
    "        return np.hstack(probs) # make into single matrix\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.unique_[np.argmax(self.predict_proba(X),axis=1)] # take argmax along row\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used this notebook from class to implement stochastic gradient descent \n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/06.%20Optimization.ipynb\n",
    "\n",
    "class StochasticLogisticRegression(BinaryLogisticRegression):\n",
    "    # stochastic gradient calculation \n",
    "    def _get_gradient(self,X,y):\n",
    "        idx = int(np.random.rand()*len(y)) # grab random instance\n",
    "        ydiff = y[idx]-self.predict_proba(X[idx],add_bias=False) # get y difference (now scalar)\n",
    "        gradient = X[idx] * ydiff[:,np.newaxis] # make ydiff a column vector and multiply through\n",
    "        \n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        #gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used this notebook from class to implement Newton's method for gradient descent \n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/06.%20Optimization.ipynb\n",
    "\n",
    "from numpy.linalg import pinv\n",
    "class HessianBinaryLogisticRegression(BinaryLogisticRegression):\n",
    "    # just overwrite gradient function\n",
    "    def _get_gradient(self,X,y):\n",
    "        g = self.predict_proba(X,add_bias=False).ravel() # get sigmoid value for all classes\n",
    "        hessian = X.T @ np.diag(g*(1-g)) @ X - 2 * self.C # calculate the hessian\n",
    "\n",
    "        ydiff = y-g # get y difference\n",
    "        gradient = np.sum(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        #gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return pinv(hessian) @ gradient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used notebook from class to implement L2 Regularized Logistic Regression\n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/05.%20Logistic%20Regression.ipynb\n",
    "\n",
    "class RegularizedBinaryLogisticRegression(VectorBinaryLogisticRegression):\n",
    "    # extend init functions\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "        \n",
    "    # extend previous class to change functionality\n",
    "    def _get_gradient(self,X,y):\n",
    "        # call get gradient from previous class\n",
    "        gradient = super()._get_gradient(X,y)\n",
    "        \n",
    "        # add in regularization (to all except bias term)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        return gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used notebook from class to implement L2 Regularized Logistic Regression\n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/05.%20Logistic%20Regression.ipynb\n",
    "\n",
    "# now redefine the Logistic Regression Function where needed\n",
    "class RegularizedLogisticRegression(LogisticRegression):\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.unique_ = np.unique(y) # get each unique class value\n",
    "        num_unique_classes = len(self.unique_)\n",
    "        self.classifiers_ = [] # will fill this array with binary classifiers\n",
    "        \n",
    "        for i,yval in enumerate(self.unique_): # for each unique value\n",
    "            y_binary = y==yval # create a binary problem\n",
    "            # train the binary classifier for this class\n",
    "            blr = RegularizedBinaryLogisticRegression(eta=self.eta,\n",
    "                                                      iterations=self.iters,\n",
    "                                                      C=self.C)\n",
    "            blr.fit(X,y_binary)\n",
    "            # add the trained classifier to the list\n",
    "            self.classifiers_.append(blr)\n",
    "            \n",
    "        # save all the weights into one matrix, separate column for each class\n",
    "        self.w_ = np.hstack([x.w_ for x in self.classifiers_]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used notebook from class to implement L2 Regularized Logistic Regression\n",
    "#https://github.com/eclarson/MachineLearningNotebooks/blob/master/05.%20Logistic%20Regression.ipynb\n",
    "\n",
    "class RegularizedBinaryLogisticRegressionL1(VectorBinaryLogisticRegression):\n",
    "    # extend init functions\n",
    "    def __init__(self, C=0.0, **kwds):        \n",
    "        # need to add to the original initializer \n",
    "        self.C = C\n",
    "        # but keep other keywords\n",
    "        super().__init__(**kwds) # call parent initializer\n",
    "        \n",
    "        \n",
    "    # extend previous class to change functionality\n",
    "    def _get_gradient(self,X,y):\n",
    "        # call get gradient from previous class\n",
    "        gradient = super()._get_gradient(X,y)\n",
    "        \n",
    "        # add in regularization (to all except bias term)\n",
    "      \n",
    "        signs = np.zeros((len(self.w_),1))\n",
    "        \n",
    "        for s in range(1,len(self.w_)):\n",
    "            if self.w_[s] < 0:     \n",
    "                signs[s] = -1\n",
    "            elif self.w_[s] > 0:\n",
    "                signs[s] = 1\n",
    "            else:\n",
    "                signs[s] = 0\n",
    "\n",
    "        gradient[1:] -= self.C * signs[1:]\n",
    "        return gradient\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exceptional Work\n",
    "\n",
    "class MeanLogisticRegression(BinaryLogisticRegression):\n",
    "    def _get_gradient(self,X,y):\n",
    "        \n",
    "        #gradient for MeanLogisticRegression=2/m*X*[y-yhat]*yhat*(1-yhat)\n",
    "        ydiff = y-self.predict_proba(X,add_bias=False).ravel() # get y difference\n",
    "        ydiff=ydiff*self.predict_proba(X,add_bias=False).ravel()\n",
    "        ydiff=ydiff*(1-self.predict_proba(X,add_bias=False).ravel())*2/ydiff.size\n",
    "        \n",
    "        \n",
    "       # gradient = 2*np.mean(X * ydiff[:,np.newaxis], axis=0) # make ydiff a column vector and multiply through\n",
    "        gradient=np.transpose(X)@ydiff\n",
    "        gradient = gradient.reshape(self.w_.shape)\n",
    "        gradient[1:] += -2 * self.w_[1:] * self.C\n",
    "        \n",
    "        return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114078c0c87c486c8d88f65acaa1dcad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Type', options=('Standard LR', 'Regularized LR (L2)', 'Stochastic "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.on_select(Type)>"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Choosing Optimization Technique\n",
    "\n",
    "from ipywidgets import widgets\n",
    "import time\n",
    "#get_C = 0\n",
    "\n",
    "\n",
    "def printLR():\n",
    "    start = time.time()\n",
    "    lr = LogisticRegression(eta=0.01, iterations=1500)\n",
    "    lr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())\n",
    "    yhat = lr.predict(X_test.to_numpy())\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(lr)\n",
    "    print('Accuracy of: ',accuracy_score(y_test.to_numpy(),yhat))\n",
    "    print('Elaped time: %f seconds'%elapsed)\n",
    "    \n",
    "def printRLR():\n",
    "    start = time.time()\n",
    "    lr = RegularizedLogisticRegression(eta=0.01, iterations=1500)\n",
    "    lr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())\n",
    "    yhat = lr.predict(X_test.to_numpy())\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(lr)\n",
    "    print('Accuracy of: ',accuracy_score(y_test.to_numpy(),yhat))\n",
    "    print('Elaped time: %f seconds'%elapsed)\n",
    "    \n",
    "def printSLR():\n",
    "    start = time.time()\n",
    "    slr = StochasticLogisticRegression(0.05,500) # take a lot more steps!!\n",
    "    slr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())\n",
    "    yhat = slr.predict(X_test.to_numpy())\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(slr)\n",
    "    print('Accuracy of: ',accuracy_score(y_test.to_numpy(),yhat))\n",
    "    print('Elaped time: %f seconds'%elapsed)\n",
    "    \n",
    "def printHLR():\n",
    "    start = time.time()\n",
    "    hlr = HessianBinaryLogisticRegression(eta=1.0,iterations=4)\n",
    "    hlr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())   \n",
    "    yhat = hlr.predict(X_test.to_numpy()) \n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print(hlr)\n",
    "    print('Accuracy of: ',accuracy_score(y_test.to_numpy(),yhat))\n",
    "    print('Elaped time: %f seconds'%elapsed)\n",
    "    \n",
    "def printMLR():\n",
    "    start = time.time()\n",
    "    mlr = MeanLogisticRegression(0.05,500)\n",
    "    mlr.fit(X_train.to_numpy(),(y_train.quality_rating.to_numpy()))\n",
    "    print(mlr)\n",
    "    yhat = mlr.predict(X_test.to_numpy())\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    print('Accuracy of: ',accuracy_score(y_test.to_numpy(),yhat))\n",
    "    print('Elaped time: %f seconds'%elapsed)\n",
    "    \n",
    "\n",
    "def on_select(Type):\n",
    "    if Type == 'Standard LR':\n",
    "        printLR()\n",
    "    elif Type == 'Regularized LR (L2)':\n",
    "        printRLR()\n",
    "    elif Type == 'Stochastic LR':\n",
    "        printSLR()\n",
    "    elif Type == 'Hessian LR':\n",
    "        printHLR()\n",
    "    elif Type == 'Mean^2 LR':\n",
    "        printMLR()\n",
    "        \n",
    "widgets.interact(on_select, Type = ['Standard LR','Regularized LR (L2)','Stochastic LR','Hessian LR','Mean^2 LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "< Timing and Accuracy for all methods >\n",
      "Standard Logistic Regression\n",
      "Accuracy of:  0.44693877551020406\n",
      "Elapsed time: 1.901665 seconds\n",
      "Regularized Logistic Regression (L2)\n",
      "Accuracy of:  0.44693877551020406\n",
      "Elapsed time: 2.092070 seconds\n",
      "Stochastic Logistic Regression\n",
      "Accuracy of:  0.0336734693877551\n",
      "Elapsed time: 0.015636 seconds\n",
      "Hessian Logistic Regression\n",
      "Accuracy of:  0.0336734693877551\n",
      "Elapsed time: 0.320887 seconds\n",
      "Mean Squared Logistic Regression\n",
      "Accuracy of:  0.0336734693877551\n",
      "Elapsed time: 0.250142 seconds\n"
     ]
    }
   ],
   "source": [
    "print('< Timing and Accuracy for all methods >')\n",
    "\n",
    "start = time.time()\n",
    "lr = LogisticRegression(eta=0.01, iterations=1500,C=.01)\n",
    "lr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())\n",
    "yhat = lr.predict(X_test.to_numpy())\n",
    "end = time.time()\n",
    "elapsed1 = end - start\n",
    "accuracy1 = accuracy_score(y_test.to_numpy(),yhat)\n",
    "print('Standard Logistic Regression')\n",
    "print('Accuracy of: ',accuracy1)\n",
    "print('Elapsed time: %f seconds'%elapsed1)\n",
    "\n",
    "start = time.time()\n",
    "rlr = RegularizedLogisticRegression(eta=0.01, iterations=1500,C=.01)\n",
    "rlr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())\n",
    "yhat = rlr.predict(X_test.to_numpy())\n",
    "end = time.time()\n",
    "elapsed2 = end - start\n",
    "accuracy2 = accuracy_score(y_test.to_numpy(),yhat)\n",
    "print('Regularized Logistic Regression (L2)')\n",
    "print('Accuracy of: ',accuracy2)\n",
    "print('Elapsed time: %f seconds'%elapsed2)\n",
    "\n",
    "start = time.time()\n",
    "slr = StochasticLogisticRegression(0.05,500,C=.01) # take a lot more steps!!\n",
    "slr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())\n",
    "yhat = slr.predict(X_test.to_numpy())\n",
    "end = time.time()\n",
    "elapsed3 = end - start\n",
    "accuracy3 = accuracy_score(y_test.to_numpy(),yhat)\n",
    "print('Stochastic Logistic Regression')\n",
    "print('Accuracy of: ',accuracy3)\n",
    "print('Elapsed time: %f seconds'%elapsed3)\n",
    "\n",
    "start = time.time()\n",
    "hlr = HessianBinaryLogisticRegression(eta=1.0,iterations=4,C=.01)\n",
    "hlr.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())   \n",
    "yhat = hlr.predict(X_test.to_numpy()) \n",
    "end = time.time()\n",
    "elapsed4 = end - start\n",
    "accuracy4 = accuracy_score(y_test.to_numpy(),yhat)\n",
    "print('Hessian Logistic Regression')\n",
    "print('Accuracy of: ',accuracy4)\n",
    "print('Elapsed time: %f seconds'%elapsed4)\n",
    "\n",
    "start = time.time()\n",
    "mlr = MeanLogisticRegression(0.05,500,C=1)\n",
    "mlr.fit(X_train.to_numpy(),(y_train.quality_rating.to_numpy()))\n",
    "yhat = mlr.predict(X_test.to_numpy())\n",
    "end = time.time()\n",
    "elapsed5 = end - start\n",
    "accuracy5 = accuracy_score(y_test.to_numpy(),yhat)\n",
    "print('Mean Squared Logistic Regression')\n",
    "print('Accuracy of: ',accuracy5)\n",
    "print('Elapsed time: %f seconds'%elapsed5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.76692134  2.05707698  4.35382936 -0.31352398 -2.81753241 -0.2189971\n",
      "  -2.04925394 -1.99699308 -0.20924572  0.47108488 -0.44843278 -2.33922667]\n",
      " [ 0.51101801  0.35671256  3.38129746 -0.10092385 -2.0392331   0.69220364\n",
      "  -1.40874457  1.30265709  0.40984188 -0.48073128 -0.9300138  -4.90651223]\n",
      " [ 0.01839423 -0.5553926  -3.18462596  0.23947417  0.97087844  0.29044754\n",
      "   0.2976071  -0.14347161  0.57617072 -0.22695799  0.12028066  0.92849981]\n",
      " [-2.86784193 -0.21099619 -3.10753479 -0.86726123  2.17684375 -2.76455182\n",
      "   1.60374473 -0.80158956 -1.22661074  0.86372987  0.83213337  4.51755902]]\n",
      "Accuracy of:  0.5489795918367347\n",
      "Elapsed Time:  0.052093505859375\n"
     ]
    }
   ],
   "source": [
    "#sklearn implementation for comparison\n",
    "from sklearn.linear_model import LogisticRegression as SKLogisticRegression\n",
    "\n",
    "start = time.time()\n",
    "lr_sk = SKLogisticRegression(solver='liblinear') # all params default\n",
    "\n",
    "lr_sk.fit(X_train.to_numpy(),y_train.quality_rating.to_numpy())\n",
    "print(np.hstack((lr_sk.intercept_[:,np.newaxis],lr_sk.coef_)))\n",
    "yhat = lr_sk.predict(X_test.to_numpy())\n",
    "end = time.time()\n",
    "elapsed6 = end - start\n",
    "accuracy6 = accuracy_score(y_test.to_numpy(),yhat)\n",
    "print('Accuracy of: ',accuracy6)\n",
    "print('Elapsed Time: ',elapsed6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10,5]\n",
    "all_accuracy = [accuracy1,accuracy2,accuracy3,accuracy4,accuracy5,accuracy6]\n",
    "all_time = [elapsed1,elapsed2,elapsed3,elapsed4,elapsed5,elapsed6]\n",
    "reg_types = ['Standard LR', 'Regularized(L2) LR', 'Stochastic LR', 'Hessian LR', 'MS LR', 'Sklearn LR']\n",
    "colors = ['blue','red','orange','green','yellow','black']\n",
    "\n",
    "for i in range (0,len(colors)):\n",
    "    plt.scatter(all_time[i],all_accuracy[i],alpha = 0.5,c = colors[i], label = reg_types[i])\n",
    "    \n",
    "plt.legend()\n",
    "plt.title('Time vs Accuracy of Different Regression Models')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Varying Value of C\n",
    "\n",
    "Varying C did not have significant effect on the accuracy of the dataset. The most accuracy was achieved for C\n",
    "in between 0.1 and 1. Accuracy decreased only slightly even for extremely small values of C, but decreased somewhat more for large C.\n",
    "This is an indicator that our dataset migth be susceptible to underfitting. Since all attributes of the dataset have low corellations,\n",
    "overfitting is not a primary concern. Therefore, for similar type of datasets it is reasonable to assume that smaller values of \n",
    "C are needed to prevent underfitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Results of Each Optimization Technique \n",
    "\n",
    "After optimizing each of our custom regression models' parameters, the Stochastic regression was able to classify the wines the fastest, but with very little accuracy. The Hessian and MS logistic regression models ran faster than the Standard and L2 Regularized models, but also had a very low accuracy. The Standard and L2 Regularized models achieved an accuracy close to that of the Sklearn implementation of multiclass logistic regression, but it took much longer to get a less accurate result. The Sklearn logistic regression was only slower than our Stochastic regression implementation but had a much higher accuracy in a similar amount of time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deployment:\n",
    "\n",
    "The Scikit Learn implimentation of linear regression is the most usable choice for this dataset, as it producses a significantly higher accuracy than all of our implementations, while only being marginally slower than the hessian implementation. In this case, a higher accuracy will end up being more important than the minimal time difference. The accuracy for this dataset is low using any of the categorization methods (custom or Scikit Learn) and is highly dependent on how cutoff points are determined for quality. Since most of the data lies in the quality 5-6 range, if these two are considered together the learning method can always predict 5 or 6 and be very accurate, but not very useful. If qualities 5 and 6 are separated, the features for them are so similar that the program cannot truly distinguish between the two, and the accuracy is negatively affected. There are no clear indicators as to which features most correlate to the quality of the wine (seen in the correlation matrix at the beginning of the notebook), so the dataset may be difficult for any of the classifiers, either the custom regression models we implement or the SKlearn model, to classify the wines with high accuracy. If one implementation should be chosen though, it would have to be the SKlearn implementation of multiclass logistic regression due to improved accuracy and minimal compute time.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
